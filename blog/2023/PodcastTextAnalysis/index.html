<!DOCTYPE html>
<!-- _layouts/distill.html --><html>
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>随机波动 (StochasticVolatility) Analysis Using NLP and Machine Learning | Øscar  Wu</title>
    <meta name="author" content="Øscar  Wu">
    <meta name="description" content="Uncover the power of natural language processing (NLP) and machine learning techniques in analyzing 随机波动 Stochastic Volatility podcasts. Delve into the complete workflow, from data collection and audio transcription to text preprocessing, analysis, and visualization, to gain valuable insights on podcast topics, emotions, and overall content.">
    <meta name="keywords" content="data science, mathematics, machine learning, portfolio, academic website, Jekyll, al-folio, GitHub Pages">


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous">

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700%7CRoboto+Slab:100,300,400,500,700%7CMaterial+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light">

    <!-- Styles -->
    
    <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%C3%98&lt;/text&gt;&lt;/svg&gt;">
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="https://wuyoscar.github.io/blog/2023/PodcastTextAnalysis/">
    
    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark">

    <script src="/assets/js/theme.js"></script>
    <script src="/assets/js/dark_mode.js"></script>
    


    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    <!-- Distill js -->
    <script src="/assets/js/distillpub/template.v2.js"></script>
    <script src="/assets/js/distillpub/transforms.v2.js"></script>
    <script src="/assets/js/distillpub/overrides.js"></script>
    
    <!-- Page/Post style -->
    <style type="text/css">
      .fake-img {
  background: #bbb;
  border: 1px solid rgba(0, 0, 0, 0.1);
  box-shadow: 0 0px 4px rgba(0, 0, 0, 0.1);
  margin-bottom: 12px;
} .fake-img p {
  font-family: monospace;
  color: white;
  text-align: left;
  margin: 12px 0;
  text-align: center;
  font-size: 10px;
}

      /* Custom CSS for distill title size */
      d-title h1 {
        font-size: 1.95rem;
      }
    </style>
  </head>

  <body>
<d-front-matter>
    <script async type="text/json">{
      "title": "随机波动 (StochasticVolatility) Analysis Using NLP and Machine Learning",
      "description": "Uncover the power of natural language processing (NLP) and machine learning techniques in analyzing 随机波动 Stochastic Volatility podcasts. Delve into the complete workflow, from data collection and audio transcription to text preprocessing, analysis, and visualization, to gain valuable insights on podcast topics, emotions, and overall content.",
      "published": "April 27, 2023",
      "authors": [
        {
          "author": "Oscar Wu",
          "authorURL": "wuyoscar.github.io",
          "affiliations": [
            {
              "name": "Personal Blog",
              "url": ""
            }
          ]
        },
        {
          "author": "Yika Gu",
          "authorURL": "",
          "affiliations": [
            {
              "name": "Deakin University",
              "url": ""
            }
          ]
        }
        
      ],
      "katex": {
        "delimiters": [
          {
            "left": "$",
            "right": "$",
            "display": false
          },
          {
            "left": "$$",
            "right": "$$",
            "display": true
          }
        ]
      }
    }</script>
  </d-front-matter>

  

    <!-- Header --><header>

  <!-- Nav Bar -->
  <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Øscar </span>Wu</a>
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>

      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">

          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/">About</a>
          </li>
          
          <!-- Blog -->
          <li class="nav-item active">
            <a class="nav-link" href="/blog/">Blog<span class="sr-only">(current)</span></a>
          </li>

          <!-- Other pages -->
          <li class="nav-item ">
            <a class="nav-link" href="/repositories/">Repositories</a>
          </li>
          <li class="nav-item ">
            <a class="nav-link" href="/cv/">Vitae</a>
          </li>

          <!-- Toogle theme mode -->
          <li class="toggle-container">
            <button id="light-toggle" title="Change theme">
              <i class="fas fa-moon"></i>
              <i class="fas fa-sun"></i>
            </button>
          </li>
        </ul>
      </div>
    </div>
  </nav>

  <!-- Scrolling Progress Bar -->
  <progress id="progress" value="0">
    <div class="progress-container">
      <span class="progress-bar"></span>
    </div>
  </progress>
</header>

    <!-- Content -->
    <div class="post distill">

      <d-title>
        <h1>随机波动 (StochasticVolatility) Analysis Using NLP and Machine Learning</h1>
        <p>Uncover the power of natural language processing (NLP) and machine learning techniques in analyzing 随机波动 Stochastic Volatility podcasts. Delve into the complete workflow, from data collection and audio transcription to text preprocessing, analysis, and visualization, to gain valuable insights on podcast topics, emotions, and overall content.</p>
      </d-title>

      <d-byline></d-byline>

      <d-article>
        <d-contents>
          <nav class="l-text figcaption">
          <h3>Contents</h3>
            <div><a href="#introduction">Introduction</a></div>
            <div><a href="#collecting-podcast-data">Collecting Podcast Data</a></div>
            <div><a href="#transcribing-podcast-audio-to-text">Transcribing Podcast Audio to Text</a></div>
            <div><a href="#validating-the-transcription-results">Validating the Transcription Results</a></div>
            <div><a href="#preprocessing-the-chinese-text-data">Preprocessing the Chinese Text Data</a></div>
            <div><a href="#analyzing-the-text-data">Analyzing the Text Data</a></div>
            <div><a href="#visualizing-the-results">Visualizing the Results</a></div>
            <div><a href="#conclusion">Conclusion</a></div>
            
          </nav>
        </d-contents>

        <h2 id="introduction">Introduction</h2>
<p>Podcasts are a popular form of media, offering listeners the opportunity to learn, be entertained, and stay informed. However, analyzing a podcast can be a time-consuming and challenging task, especially if you have a lot of episodes to review. In this blog post, we’ll explore how to use natural language processing (NLP) and machine learning to analyze a podcast. By applying these techniques, we can gain insights into the topics discussed, the emotions expressed, and the overall content of the podcast. We’ll cover the entire process, from collecting the podcast data to visualizing the results. So, let’s get started!</p>

<p><a href="https://www.stovol.club/" rel="external nofollow noopener" target="_blank">Stochastic Volatility</a> is a cross-cultural podcast initiated by three female media professionals. Today, I will use the Stochastic Volatility as an example to show you how to analyze a podcast using NLP and machine learning techniques.</p>

<div class="l-body">
    <figure>
    <a href="https://www.stovol.club/" rel="external nofollow noopener" target="_blank">
      <img src="/assets/img/2023-04/%E9%9A%8F%E6%9C%BA%E6%B3%A2%E5%8A%A8.png" alt="Image description">
      <figcaption>This is a caption for the image.</figcaption>
      </a>
    </figure>
  </div>

<h2 id="collecting-podcast-data">Collecting Podcast Data</h2>

<p>At Stochastic Volatility, we have selected three episodes with themes related to <code class="language-plaintext highlighter-rouge">Feminism</code> for analysis. These episodes cover a range of topics related to women, such as gender equality, feminism, and women’s roles in society. By using NLP and machine learning techniques to analyze the text data of these episodes, we hope to gain deeper insights into the discussions and perspectives presented on these important topics.</p>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0 mb-4">
        <a href="https://www.stovol.club/096" target="_blank" rel="external nofollow noopener">
            <img src="/assets/img/2023-04/%E9%9A%8F%E6%9C%BA%E6%B3%A2%E5%8A%A8_96.png" class="img-fluid rounded z-depth-1" data-action="zoom">
        </a>
    </div>
    <div class="col-sm mt-3 mt-md-0 mb-4">
        <a href="https://www.stovol.club/094" target="_blank" rel="external nofollow noopener">
            <img src="/assets/img/2023-04/%E9%9A%8F%E6%9C%BA%E6%B3%A2%E5%8A%A8_94.png" class="img-fluid rounded z-depth-1" data-action="zoom">
        </a>
    </div>
    <div class="col-sm mt-3 mt-md-0 mb-4">
        <a href="https://www.stovol.club/085" target="_blank" rel="external nofollow noopener">
            <img src="/assets/img/2023-04/%E9%9A%8F%E6%9C%BA%E6%B3%A2%E5%8A%A8_85.png" class="img-fluid rounded z-depth-1" data-action="zoom">
        </a>
    </div>
</div>

<p>As you can see, the average duration of each episode is <strong>1 hrs 30mins</strong>, which means that we have to spend roughly <strong>4 hrs 30mins</strong> to listen to these three episodes. However, we can use NLP and machine learning techniques to analyze the text data of these episodes, which will save us a lot of time. However, before we can analyze the text data, we need to transcribe the audio to text. Next, we’ll explore how to do this.</p>

<h2 id="transcribing-podcast-audio-to-text">Transcribing Podcast Audio to Text</h2>
<p>To transcribe Chinese audio to text, there are several options available. Here are three popular choices:</p>

<ul>
  <li>
    <p>Baidu Speech Recognition API: This is a speech recognition service provided by Baidu, a Chinese tech giant. It supports Chinese and can transcribe audio to text in real-time. It is relatively accurate and has a free trial with a limited amount of transcription time per month.</p>
  </li>
  <li>
    <p>iFlytek Speech Recognition API: This is a speech recognition service provided by iFlytek, a leading Chinese AI company. It supports Chinese and can transcribe audio to text with high accuracy. It has a free trial with a limited amount of transcription time per day.</p>
  </li>
  <li>
    <p>Google Cloud Speech-to-Text API: This is a speech recognition service provided by Google Cloud, which supports several languages including Chinese. It has high accuracy and can transcribe long-form audio. However, it is a paid service and can be expensive for large amounts of transcription.</p>
  </li>
</ul>

<p>To use these services, you will need to register for an account, obtain API keys, and then integrate them into your transcription workflow. Once you have integrated the service of your choice, you can transcribe your Chinese audio to text by uploading or streaming the audio to the API, which will return the text transcription. Here, we will use the Google Cloud Speech-to-Text API to transcribe our podcast audio to text.</p>

<h3 id="setting-up-google-cloud-speech-to-text-api">Setting up Google Cloud Speech-to-Text API</h3>
<p>To use the Google Cloud Speech-to-Text API, you will need to set up a Google Cloud account and create a project. Then, you will need to enable the Speech-to-Text API and create a service account. Finally, you will need to download the service account key file and set the environment variable <code class="language-plaintext highlighter-rouge">GOOGLE_APPLICATION_CREDENTIALS</code> to the path of the key file. For more detailed instructions, please refer to the <a href="https://cloud.google.com/speech-to-text/docs/quickstart-client-libraries" rel="external nofollow noopener" target="_blank">Google Cloud Speech-to-Text API documentation</a>:</p>
<ol>
  <li>
    <p>Login in to your Google Cloud account and create a project, then click <code class="language-plaintext highlighter-rouge">Dashboard</code> to go to the project dashboard:</p>

    <div class="l-body">
<figure>
   <img src="/assets/img/2023-04/gcc_step1.png" alt="This is a caption for the image.">
</figure>
</div>
  </li>
  <li>
    <p>In the left navigation panel, click on “APIs &amp; Services” &gt; “Dashboard”. Click on + <code class="language-plaintext highlighter-rouge">ENABLE APIS AND SERVICES</code> at the top of the page.</p>
  </li>
  <li>
    <p>Search <code class="language-plaintext highlighter-rouge">Cloud Speech-to-Text API &amp; Cloud Storage API</code> and click on it. Click on <code class="language-plaintext highlighter-rouge">ENABLE</code> to enable the API.</p>

    <div class="l-body">
<figure>
   <img src="/assets/img/2023-04/gcc_step2.png" alt="This is a caption for the image.">
   </figure>
</div>
  </li>
  <li>
    <p>In the left navigation panel, click <code class="language-plaintext highlighter-rouge">Credentials</code>, and create a select <code class="language-plaintext highlighter-rouge">Service account</code>, you can choose download your credentials by <code class="language-plaintext highlighter-rouge">json</code> and store it in your local folder.</p>

    <div class="l-body">
<figure>
   <img src="/assets/img/2023-04/gcc_step3.png" alt="This is a caption for the image.">
   </figure>
</div>
  </li>
</ol>

<h3 id="test-the-google-cloud-speech-to-text-api">Test the Google Cloud Speech-to-Text API</h3>
<p>Before transcribing entire episodes, we can test the Google Cloud Speech-to-Text API on a short audio clip. To do this, we can use the <code class="language-plaintext highlighter-rouge">30sec_example.mp3</code> audio file to get start.
<code class="language-plaintext highlighter-rouge">speech.RecognitionAudio</code> and <code class="language-plaintext highlighter-rouge">speech.RecognitionConfig</code> are required to use the Google Cloud Speech-to-Text API. <code class="language-plaintext highlighter-rouge">speech.RecognitionAudio</code> is used to specify the audio file to be transcribed, and <code class="language-plaintext highlighter-rouge">speech.RecognitionConfig</code> is used to specify the language code and audio encoding of the audio file. The language code for Chinese is <code class="language-plaintext highlighter-rouge">zh-CN</code>, and the audio encoding for MP3 is <code class="language-plaintext highlighter-rouge">MP3</code>.</p>
<details><summary>Test example code</summary>
<d-code language="python">
pip install --upgrade google-cloud-speech
pip install --upgrade google-cloud-storage

# Import required libraries
import os
from google.cloud import speech_v1p1beta1 as speech
import soundfile as sf

# Set environment variable for Google Cloud authentication
os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = 'path/to/your/credentials.json'

# Initialize the Google Cloud Speech-to-Text client
speech_client = speech.SpeechClient()

# Define the paths for the MP3 and FLAC audio files
media_file_name_mp3 = '/Users/wuyoscar/Downloads/exmaple.mp3'
media_file_name_flac = '/Users/wuyoscar/Downloads/exmaple.flac'

# Read audio data and sample rate from the FLAC file using the soundfile library
audio_flac, sample_rate_flac = sf.read(media_file_name_flac)

# Get the number of audio channels from the FLAC file using the soundfile library
flac_info = sf.info(media_file_name_flac)
num_channels_flac = flac_info.channels

# Read the contents of the FLAC file into a RecognitionAudio object
with open(media_file_name_flac, 'rb') as f:
    audio_flac = speech.RecognitionAudio(content=f.read())

# Read the contents of the MP3 file into a RecognitionAudio object
with open(media_file_name_mp3, 'rb') as f:
    audio_mp3 = speech.RecognitionAudio(content=f.read())

# Set up the recognition config object for the MP3 file with the required parameters
config_mp3 = speech.RecognitionConfig(
    sample_rate_hertz=44100,
    language_code="zh-CN"
)

# Set up the recognition config object for the FLAC file with the correct number of channels and other parameters
config_flac = speech.RecognitionConfig(
    encoding=speech.RecognitionConfig.AudioEncoding.FLAC,
    sample_rate_hertz=sample_rate_flac,
    audio_channel_count=num_channels_flac,
    language_code="cmn-Hans-CN"
)

speech_client.recognize(
    config=config_mp3, 
    audio=audio_mp3
)

</d-code>
</details>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">results</span> <span class="p">{</span>
  <span class="n">alternatives</span> <span class="p">{</span>
    <span class="n">transcript</span><span class="p">:</span> <span class="s">"Hello大家好我叫Oscar,我来自中国重庆很高兴认识大家,在这里希望跟大家开始一段学习旅程"</span>
    <span class="n">confidence</span><span class="p">:</span> <span class="mf">0.950523674</span>
  <span class="p">}</span>
  <span class="n">result_end_time</span> <span class="p">{</span>
    <span class="n">seconds</span><span class="p">:</span> <span class="mi">13</span>
    <span class="n">nanos</span><span class="p">:</span> <span class="mi">920000000</span>
  <span class="p">}</span>
  <span class="n">language_code</span><span class="p">:</span> <span class="s">"cmn-hans-cn"</span>
<span class="p">}</span>
<span class="n">total_billed_time</span> <span class="p">{</span>
  <span class="n">seconds</span><span class="p">:</span> <span class="mi">14</span>
<span class="p">}</span>
<span class="n">request_id</span><span class="p">:</span> <span class="mi">5898031208</span><span class="c1">######
</span></code></pre></div></div>

<h3 id="transcribe-the-entire-episode">Transcribe the entire episode</h3>

<p>Now that we have tested the Google Cloud Speech-to-Text API on a short audio clip, we can transcribe the entire episode. To do this, we can use the <code class="language-plaintext highlighter-rouge">transcribe_audio</code> function to transcribe the audio file and save the transcription to a text file. The <code class="language-plaintext highlighter-rouge">transcribe_audio</code> function is as following:</p>

<p>Table below is Reference for selected <a href="https://cloud.google.com/speech-to-text/docs/reference/rpc/google.cloud.speech.v1p1beta1#recognitionconfig" rel="external nofollow noopener" target="_blank">parameters</a> :</p>

<table>
  <thead>
    <tr>
      <th>Name</th>
      <th style="text-align: left">Desc</th>
      <th style="text-align: center">Variable</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">load_custom_phrases</code></td>
      <td style="text-align: left">You can create phrases and store list in yaml file</td>
      <td style="text-align: center">Function</td>
    </tr>
    <tr>
      <td>
<code class="language-plaintext highlighter-rouge">create_adaptation_resources</code> (<strong>skip</strong>)</td>
      <td style="text-align: left">By utilizing the model adaptation function, you can specify the words and/or phrases that Speech-to-Text must recognize more frequently in the audio data, without suggesting other potentially suitable alternative expressions.</td>
      <td style="text-align: center">Function</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">upload_blob</code></td>
      <td style="text-align: left">If audio file is more than 1 mins, you need upload to file into <em>Cloud Storage</em>
</td>
      <td style="text-align: center">Function</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">language_code</code></td>
      <td style="text-align: left"><a href="https://cloud.google.com/speech-to-text/docs/speech-to-text-supported-languages" rel="external nofollow noopener" target="_blank">speech-to-text-supported-languages</a></td>
      <td style="text-align: center">Fcuntion Parameter</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">bucket_name</code></td>
      <td style="text-align: left">Name of the Google Cloud Storage bucket</td>
      <td style="text-align: center">Google Cloud Variable</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">file_path</code></td>
      <td style="text-align: left">Path to the audio file to be transcribed</td>
      <td style="text-align: center">Audio File</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">credentials_path</code></td>
      <td style="text-align: left">path to service account credential</td>
      <td style="text-align: center">Google Cloud Variable</td>
    </tr>
  </tbody>
</table>

<details><summary>Wrap everything together and custmoize configuration based on content</summary>
<d-code language="python">
from google.cloud import speech_v1p1beta1 as speech
from google.cloud import storage
import os
import yaml

credentials_path = "path/to/your/credentials.json"
os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = credentials_path

load_custom_phrases_path = 'path/to/your/custom_phrases.yaml'
project_id = "your-project-id"
location = "global"
custom_class_id = "mycustomclass01"
phrase_set_id = "myphraseset01"


def load_custom_phrases(file_path=load_custom_phrases_path):
    with open(file_path, 'r', encoding='utf-8') as file:
        return yaml.safe_load(file)



def upload_blob(bucket_name, source_file_name, destination_blob_name):
    """Uploads a file to the bucket."""
    storage_client = storage.Client.from_service_account_json(credentials_path)
    bucket = storage_client.get_bucket(bucket_name)
    blob = bucket.blob(destination_blob_name)

    blob.upload_from_filename(source_file_name)
    print(f"File {source_file_name} uploaded to {destination_blob_name}.")


def transcribe_audio_file(bucket_name, file_path, phrases):
    destination_blob_name = os.path.basename(file_path)
    storage_client = storage.Client.from_service_account_json(credentials_path)
    bucket = storage_client.get_bucket(bucket_name)
    blob = bucket.blob(destination_blob_name)

    if not blob.exists():
        upload_blob(bucket_name, file_path, destination_blob_name)
    else:
        print(f"File {destination_blob_name} already exists in the bucket.")

    client = speech.SpeechClient.from_service_account_json(credentials_path)

    config = speech.RecognitionConfig(
        encoding=speech.RecognitionConfig.AudioEncoding.MP3,
        sample_rate_hertz=44100,
        audio_channel_count=3,
        language_code="zh-CN",
        enable_automatic_punctuation=True,
        enable_separate_recognition_per_channel=True,
        use_enhanced=True,
        enable_speaker_diarization=True,
        diarization_speaker_count=3,
        speech_contexts=[{"phrases": phrases}],
    )

    storage_uri = f"gs://{bucket_name}/{destination_blob_name}"
    audio = speech.RecognitionAudio(uri=storage_uri)

    operation = client.long_running_recognize(config=config, audio=audio)
    print("Waiting for operation to complete...")

    timeout_seconds = 7200
    response = operation.result(timeout=timeout_seconds)
    return response

def save_response_to_file(response, output_file):
    with open(output_file, 'w', encoding='utf-8') as f:
        for index, result in enumerate(response.results):
            # Choose the first alternative (most likely) from the list of alternatives
            alternative = result.alternatives[0]
            transcript = alternative.transcript
             #skip empty string and only save the frist transcript
            if transcript.strip() and index % 2 != 0 :
                print(transcript.strip())
                f.write(transcript + '\n')
    print(f"Transcript saved to {output_file}")

</d-code>
</details>

<h2 id="validating-the-transcription-results-via-chatgpt-4-modwel">Validating the Transcription Results via ChatGPT-4 Modwel</h2>
<p>After successfully transcribing the audio content of the “Stochastic Volatility” podcast into text using a speech-to-text API, we need to preprocess the text data. This step is crucial because it helps clean up and format the raw text, allowing our machine learning model to understand and process the content more effectively.</p>

<p>However, upon examining the transcribed text, I noticed two major inaccuracies:</p>

<ol>
  <li>In this text snippet, the names “服饰演”, “张知其”, and “冷见过” were incorrectly recognized. The correct names should be “傅适野”, “张之琪”, and “冷建国”.
    <div class="language-javascript highlighter-rouge">
<div class="highlight"><pre class="highlight"><code><span class="nx">各位听众朋友大家好</span><span class="err">，</span><span class="nx">欢迎收听星期的随机波动</span><span class="err">，</span><span class="nx">我是服饰演我是张知其我是冷见过你怎么还吃</span>
</code></pre></div>    </div>
  </li>
  <li>The Chinese text segmentation is not very accurate, leading to missing periods and commas, which makes the sentence meaning unclear.
    <div class="language-javascript highlighter-rouge">
<div class="highlight"><pre class="highlight"><code><span class="p">...</span><span class="nx">精神上已经就是不是特别稳定了</span><span class="err">，</span><span class="nx">就是中中间经历了崩</span><span class="err">。</span><span class="nx">会大哭这样的一个过程</span>
</code></pre></div>    </div>
  </li>
  <li>The text has issues with Chinese punctuation, such as missing periods and commas, which affect the clarity and readability of the content.</li>
</ol>

<p>To address these issues, we can use ChatGPT, a deep learning model, to correct the recognition errors, add missing punctuation, and improve the overall quality of the text. Although many pre-trained models can perform these tasks, they are mostly designed for English text. In this case, we’ll use ChatGPT, which can also handle Chinese text</p>

<h3 id="constructing-useful-prompt">Constructing useful Prompt</h3>
<p>In your correct_text function, you are using ChatGPT to correct grammar errors, add punctuation, and fix recognition errors in the given Chinese text. The function takes the transcribed text as input, sends it to the ChatGPT API along with a prompt that explains the task, and then returns the corrected and punctuated text.</p>

<h4 id="system-message">System message:</h4>
<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="nl">"role"</span><span class="p">:</span><span class="w"> </span><span class="s2">"system"</span><span class="p">,</span><span class="w"> </span><span class="nl">"content"</span><span class="p">:</span><span class="w"> </span><span class="s2">"You are a helpful assistant that corrects grammar errors, adds punctuation, and fixes recognition errors in Chinese text."</span><span class="p">}</span><span class="w">
</span></code></pre></div></div>
<p>This message sets the context for the ChatGPT model, informing it that its role is to be a helpful assistant, responsible for correcting grammar errors, adding punctuation, and fixing recognition errors in the Chinese text.</p>
<h4 id="user-message-background-information">User message (background information):</h4>
<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="nl">"role"</span><span class="p">:</span><span class="w"> </span><span class="s2">"user"</span><span class="p">,</span><span class="w"> </span><span class="nl">"content"</span><span class="p">:</span><span class="w"> </span><span class="s2">"This text is from a cross-cultural podcast initiated by three female media professionals."</span><span class="p">}</span><span class="w">

</span></code></pre></div></div>
<p>This message provides the model with background information about the input text. By mentioning that the text comes from a cross-cultural podcast initiated by three female media professionals, you give the model additional context that might help improve the quality of the generated corrections and adjustments.</p>

<h4 id="user-message-task-instructions">User message (task instructions):</h4>
<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="nl">"role"</span><span class="p">:</span><span class="w"> </span><span class="s2">"user"</span><span class="p">,</span><span class="w"> </span><span class="nl">"content"</span><span class="p">:</span><span class="w"> </span><span class="err">f</span><span class="s2">"Please correct any grammar errors, add punctuation, and fix the recognition errors in the following Chinese text:</span><span class="se">\n</span><span class="s2">{text}</span><span class="se">\n\n</span><span class="s2">For example, the host name is '傅适野，张之琪，冷建国', and there might be missing punctuation like commas and periods. Make the text clear and easy to understand."</span><span class="p">}</span><span class="w">

</span></code></pre></div></div>
<p>This message gives specific instructions for the task. It asks the model to correct grammar errors, add punctuation, and fix recognition errors in the input text. It also provides an example of correctly recognized host names and mentions possible issues with missing punctuation like commas and periods. This helps the model understand the desired output and ensures that the text is clear and easy to understand after the corrections are made.</p>

<h2 id="preprocessing-the-chinese-text-data">Preprocessing the Chinese Text Data</h2>
<p>In this section, we will cover the following preprocessing techniques:</p>
<ol>
  <li>Tokenization</li>
  <li>Removing stop words</li>
  <li>Removing special characters and numbers</li>
  <li>Lowercasing</li>
  <li>Lemmatization</li>
</ol>

<h3 id="tokenization">Tokenization</h3>
<p>Tokenization is the process of breaking down the text into individual words or tokens. For Chinese text, we will use the Jieba library for tokenization.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">jieba</span>
<span class="k">def</span> <span class="nf">tokenize_chinese_text</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="n">tokens</span> <span class="o">=</span> <span class="n">jieba</span><span class="p">.</span><span class="nf">lcut</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">tokens</span>

</code></pre></div></div>

<h3 id="removing-stop-words">Removing stop words</h3>
<p>Stop words are common words that do not carry much meaning and can be removed from the text to reduce noise. You can either create a custom list of Chinese stop words or find an existing list online. Load the stop words into a Python set for efficient filtering.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">load_stop_words</span><span class="p">(</span><span class="n">file_path</span><span class="p">):</span>
    <span class="k">with</span> <span class="nf">open</span><span class="p">(</span><span class="n">file_path</span><span class="p">,</span> <span class="s">'r'</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s">'utf-8'</span><span class="p">)</span> <span class="k">as</span> <span class="nb">file</span><span class="p">:</span>
        <span class="n">stop_words</span> <span class="o">=</span> <span class="nf">set</span><span class="p">(</span><span class="n">line</span><span class="p">.</span><span class="nf">strip</span><span class="p">()</span> <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="nb">file</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">stop_words</span>

<span class="n">stop_words_file_path</span> <span class="o">=</span> <span class="s">'path/to/chinese_stop_words.txt'</span>
<span class="n">stop_words</span> <span class="o">=</span> <span class="nf">load_stop_words</span><span class="p">(</span><span class="n">stop_words_file_path</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">remove_stop_words</span><span class="p">(</span><span class="n">tokens</span><span class="p">,</span> <span class="n">stop_words</span><span class="p">):</span>
    <span class="n">cleaned_tokens</span> <span class="o">=</span> <span class="p">[</span><span class="n">word</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">tokens</span> <span class="k">if</span> <span class="n">word</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">stop_words</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">cleaned_tokens</span>

</code></pre></div></div>

<h3 id="removing-special-characters-and-numbers">Removing special characters and numbers</h3>
<p>We will remove any special characters, numbers, and whitespace from the tokens to further clean the text.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">remove_special_characters_and_numbers</span><span class="p">(</span><span class="n">tokens</span><span class="p">):</span>
    <span class="n">cleaned_tokens</span> <span class="o">=</span> <span class="p">[</span><span class="n">word</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">tokens</span> <span class="k">if</span> <span class="n">word</span><span class="p">.</span><span class="nf">strip</span><span class="p">()</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">word</span><span class="p">.</span><span class="nf">isdigit</span><span class="p">()]</span>
    <span class="k">return</span> <span class="n">cleaned_tokens</span>
</code></pre></div></div>

<h3 id="preprocessing-pipeline">Preprocessing Pipeline</h3>
<p>Now, we will create a preprocessing pipeline that combines all the above techniques. The pipeline takes raw Chinese text as input and returns cleaned tokens.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">preprocess_chinese_text</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">stop_words</span><span class="p">):</span>
    <span class="c1"># Tokenize
</span>    <span class="n">tokens</span> <span class="o">=</span> <span class="nf">tokenize_chinese_text</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>

    <span class="c1"># Remove stop words
</span>    <span class="n">tokens</span> <span class="o">=</span> <span class="nf">remove_stop_words</span><span class="p">(</span><span class="n">tokens</span><span class="p">,</span> <span class="n">stop_words</span><span class="p">)</span>

    <span class="c1"># Remove special characters and numbers
</span>    <span class="n">cleaned_tokens</span> <span class="o">=</span> <span class="nf">remove_special_characters_and_numbers</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">cleaned_tokens</span>

<span class="n">file_path</span> <span class="o">=</span> <span class="s">"path/to/your/txt_file.txt"</span>
<span class="n">text</span> <span class="o">=</span> <span class="nf">read_text_file</span><span class="p">(</span><span class="n">file_path</span><span class="p">)</span>
<span class="n">preprocessed_tokens</span> <span class="o">=</span> <span class="nf">preprocess_chinese_text</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">stop_words</span><span class="p">)</span>
</code></pre></div></div>

      </d-article>

      <d-appendix>
        <d-footnote-list></d-footnote-list>
        <d-citation-list></d-citation-list>
      </d-appendix>

      <d-bibliography src="/assets/bibliography/"></d-bibliography>
</div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        © Copyright 2023 Øscar  Wu. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>.

      </div>
    </footer>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    
    

<!-- Scrolling Progress Bar -->
<script type="text/javascript">
  /*
   * This JavaScript code has been adapted from the article 
   * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar, 
   * published on the website https://css-tricks.com on the 7th of May, 2014.
   * Couple of changes were made to the original code to make it compatible 
   * with the `al-foio` theme.
   */
  const progressBar = $("#progress");
  /*
   * We set up the bar after all elements are done loading.
   * In some cases, if the images in the page are larger than the intended
   * size they'll have on the page, they'll be resized via CSS to accomodate
   * the desired size. This mistake, however, breaks the computations as the
   * scroll size is computed as soon as the elements finish loading.
   * To account for this, a minimal delay was introduced before computing the
   * values.
   */
  window.onload = function () {
    setTimeout(progressBarSetup, 50);
  };
  /*
   * We set up the bar according to the browser.
   * If the browser supports the progress element we use that.
   * Otherwise, we resize the bar thru CSS styling
   */
  function progressBarSetup() {
    if ("max" in document.createElement("progress")) {
      initializeProgressElement();
      $(document).on("scroll", function() {
        progressBar.attr({ value: getCurrentScrollPosition() });
      });
      $(window).on("resize", initializeProgressElement);
    } else {
      resizeProgressBar();
      $(document).on("scroll", resizeProgressBar);
      $(window).on("resize", resizeProgressBar);
    }
  }
  /*
   * The vertical scroll position is the same as the number of pixels that
   * are hidden from view above the scrollable area. Thus, a value > 0 is
   * how much the user has scrolled from the top
   */
  function getCurrentScrollPosition() {
    return $(window).scrollTop();
  }

  function initializeProgressElement() {
    let navbarHeight = $("#navbar").outerHeight(true);
    $("body").css({ "padding-top": navbarHeight });
    $("progress-container").css({ "padding-top": navbarHeight });
    progressBar.css({ top: navbarHeight });
    progressBar.attr({
      max: getDistanceToScroll(),
      value: getCurrentScrollPosition(),
    });
  }
  /*
   * The offset between the html document height and the browser viewport
   * height will be greater than zero if vertical scroll is possible.
   * This is the distance the user can scroll
   */
  function getDistanceToScroll() {
    return $(document).height() - $(window).height();
  }

  function resizeProgressBar() {
    progressBar.css({ width: getWidthPercentage() + "%" });
  }
  // The scroll ratio equals the percentage to resize the bar
  function getWidthPercentage() {
    return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
  }
</script>

  
</body>
</html>
