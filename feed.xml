<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="https://wuyoscar.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://wuyoscar.github.io/" rel="alternate" type="text/html" hreflang="en" /><updated>2023-05-16T00:51:54+00:00</updated><id>https://wuyoscar.github.io/feed.xml</id><title type="html">blank</title><subtitle></subtitle><entry><title type="html">Podcasts Analysis Using NLP and Machine Learning</title><link href="https://wuyoscar.github.io/blog/2023/PodcastTextAnalysis/" rel="alternate" type="text/html" title="Podcasts Analysis Using NLP and Machine Learning" /><published>2023-04-27T00:00:00+00:00</published><updated>2023-04-27T00:00:00+00:00</updated><id>https://wuyoscar.github.io/blog/2023/PodcastTextAnalysis</id><content type="html" xml:base="https://wuyoscar.github.io/blog/2023/PodcastTextAnalysis/"><![CDATA[<h2 id="introduction">Introduction</h2>
<p>Podcasts are a popular form of media, offering listeners the opportunity to learn, be entertained, and stay informed. However, analyzing a podcast can be a time-consuming and challenging task, especially if you have a lot of episodes to review. In this blog post, we’ll explore how to use natural language processing (NLP) and machine learning to analyze a podcast. By applying these techniques, we can gain insights into the topics discussed, the emotions expressed, and the overall content of the podcast. We’ll cover the entire process, from collecting the podcast data to visualizing the results. So, let’s get started!</p>

<p><a href="https://www.stovol.club/">Stochastic Volatility</a> is a cross-cultural podcast initiated by three female media professionals. Today, I will use the Stochastic Volatility as an example to show you how to analyze a podcast using NLP and machine learning techniques.</p>

<div class="l-body">
    <figure>
    <a href="https://www.stovol.club/">
      <img src="/assets/img/2023-04/随机波动.png" alt="Image description" />
      <figcaption>This is a caption for the image.</figcaption>
      </a>
    </figure>
  </div>

<h2 id="collecting-podcast-data">Collecting Podcast Data</h2>

<p>At Stochastic Volatility, we have selected three episodes with themes related to <code class="language-plaintext highlighter-rouge">Feminism</code> for analysis. These episodes cover a range of topics related to women, such as gender equality, feminism, and women’s roles in society. By using NLP and machine learning techniques to analyze the text data of these episodes, we hope to gain deeper insights into the discussions and perspectives presented on these important topics.</p>

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        <a href="https://www.stovol.club/096" target="_blank">
                <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/2023-04/%E9%9A%8F%E6%9C%BA%E6%B3%A2%E5%8A%A8_96-480.webp" />
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/2023-04/%E9%9A%8F%E6%9C%BA%E6%B3%A2%E5%8A%A8_96-800.webp" />
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/2023-04/%E9%9A%8F%E6%9C%BA%E6%B3%A2%E5%8A%A8_96-1400.webp" />
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/2023-04/%E9%9A%8F%E6%9C%BA%E6%B3%A2%E5%8A%A8_96.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="随机波动_96" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture>

</figure>
        </a>
    </div>
    <div class="col-sm mt-3 mt-md-0">
        <a href="https://www.stovol.club/094" target="_blank">
                <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/2023-04/%E9%9A%8F%E6%9C%BA%E6%B3%A2%E5%8A%A8_94-480.webp" />
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/2023-04/%E9%9A%8F%E6%9C%BA%E6%B3%A2%E5%8A%A8_94-800.webp" />
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/2023-04/%E9%9A%8F%E6%9C%BA%E6%B3%A2%E5%8A%A8_94-1400.webp" />
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/2023-04/%E9%9A%8F%E6%9C%BA%E6%B3%A2%E5%8A%A8_94.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="随机波动_94" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture>

</figure>
        </a>
    </div>
    <div class="col-sm mt-3 mt-md-0">
        <a href="https://www.stovol.club/085" target="_blank">
                <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/2023-04/%E9%9A%8F%E6%9C%BA%E6%B3%A2%E5%8A%A8_85-480.webp" />
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/2023-04/%E9%9A%8F%E6%9C%BA%E6%B3%A2%E5%8A%A8_85-800.webp" />
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/2023-04/%E9%9A%8F%E6%9C%BA%E6%B3%A2%E5%8A%A8_85-1400.webp" />
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/2023-04/%E9%9A%8F%E6%9C%BA%E6%B3%A2%E5%8A%A8_85.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="随机波动_85" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture>

</figure>
        </a>
    </div>
</div>

<p>As you can see, the average duration of each episode is <strong>1 hrs 30mins</strong>, which means that we have to spend roughly <strong>4 hrs 30mins</strong> to listen to these three episodes. However, we can use NLP and machine learning techniques to analyze the text data of these episodes, which will save us a lot of time. However, before we can analyze the text data, we need to transcribe the audio to text. Next, we’ll explore how to do this.</p>

<h2 id="transcribing-podcast-audio-to-text">Transcribing Podcast Audio to Text</h2>
<p>To transcribe Chinese audio to text, there are several options available. Here are three popular choices:</p>

<ul>
  <li>
    <p>Baidu Speech Recognition API: This is a speech recognition service provided by Baidu, a Chinese tech giant. It supports Chinese and can transcribe audio to text in real-time. It is relatively accurate and has a free trial with a limited amount of transcription time per month.</p>
  </li>
  <li>
    <p>iFlytek Speech Recognition API: This is a speech recognition service provided by iFlytek, a leading Chinese AI company. It supports Chinese and can transcribe audio to text with high accuracy. It has a free trial with a limited amount of transcription time per day.</p>
  </li>
  <li>
    <p>Google Cloud Speech-to-Text API: This is a speech recognition service provided by Google Cloud, which supports several languages including Chinese. It has high accuracy and can transcribe long-form audio. However, it is a paid service and can be expensive for large amounts of transcription.</p>
  </li>
</ul>

<p>To use these services, you will need to register for an account, obtain API keys, and then integrate them into your transcription workflow. Once you have integrated the service of your choice, you can transcribe your Chinese audio to text by uploading or streaming the audio to the API, which will return the text transcription. Here, we will use the Google Cloud Speech-to-Text API to transcribe our podcast audio to text.</p>

<h3 id="setting-up-google-cloud-speech-to-text-api">Setting up Google Cloud Speech-to-Text API</h3>
<p>To use the Google Cloud Speech-to-Text API, you will need to set up a Google Cloud account and create a project. Then, you will need to enable the Speech-to-Text API and create a service account. Finally, you will need to download the service account key file and set the environment variable <code class="language-plaintext highlighter-rouge">GOOGLE_APPLICATION_CREDENTIALS</code> to the path of the key file. For more detailed instructions, please refer to the <a href="https://cloud.google.com/speech-to-text/docs/quickstart-client-libraries">Google Cloud Speech-to-Text API documentation</a>:</p>
<ol>
  <li>
    <p>Login in to your Google Cloud account and create a project, then click <code class="language-plaintext highlighter-rouge">Dashboard</code> to go to the project dashboard:</p>

    <div class="l-body">
<figure>
   <img src="/assets/img/2023-04/gcc_step1.png" alt="This is a caption for the image." />
</figure>
</div>
  </li>
  <li>
    <p>In the left navigation panel, click on “APIs &amp; Services” &gt; “Dashboard”. Click on + <code class="language-plaintext highlighter-rouge">ENABLE APIS AND SERVICES</code> at the top of the page.</p>
  </li>
  <li>
    <p>Search <code class="language-plaintext highlighter-rouge">Cloud Speech-to-Text API &amp; Cloud Storage API</code> and click on it. Click on <code class="language-plaintext highlighter-rouge">ENABLE</code> to enable the API.</p>

    <div class="l-body">
<figure>
   <img src="/assets/img/2023-04/gcc_step2.png" alt="This is a caption for the image." />
   </figure>
</div>
  </li>
  <li>
    <p>In the left navigation panel, click <code class="language-plaintext highlighter-rouge">Credentials</code>, and create a select <code class="language-plaintext highlighter-rouge">Service account</code>, you can choose download your credentials by <code class="language-plaintext highlighter-rouge">json</code> and store it in your local folder.</p>

    <div class="l-body">
<figure>
   <img src="/assets/img/2023-04/gcc_step3.png" alt="This is a caption for the image." />
   </figure>
</div>
  </li>
</ol>

<h3 id="test-the-google-cloud-speech-to-text-api">Test the Google Cloud Speech-to-Text API</h3>
<p>Before transcribing entire episodes, we can test the Google Cloud Speech-to-Text API on a short audio clip. To do this, we can use the <code class="language-plaintext highlighter-rouge">30sec_example.mp3</code> audio file to get start.
<code class="language-plaintext highlighter-rouge">speech.RecognitionAudio</code> and <code class="language-plaintext highlighter-rouge">speech.RecognitionConfig</code> are required to use the Google Cloud Speech-to-Text API. <code class="language-plaintext highlighter-rouge">speech.RecognitionAudio</code> is used to specify the audio file to be transcribed, and <code class="language-plaintext highlighter-rouge">speech.RecognitionConfig</code> is used to specify the language code and audio encoding of the audio file. The language code for Chinese is <code class="language-plaintext highlighter-rouge">zh-CN</code>, and the audio encoding for MP3 is <code class="language-plaintext highlighter-rouge">MP3</code>.</p>
<details><summary>Test example code</summary>
<d-code language="python">
pip install --upgrade google-cloud-speech
pip install --upgrade google-cloud-storage

# Import required libraries
import os
from google.cloud import speech_v1p1beta1 as speech
import soundfile as sf

# Set environment variable for Google Cloud authentication
os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = 'path/to/your/credentials.json'

# Initialize the Google Cloud Speech-to-Text client
speech_client = speech.SpeechClient()

# Define the paths for the MP3 and FLAC audio files
media_file_name_mp3 = '/Users/wuyoscar/Downloads/exmaple.mp3'
media_file_name_flac = '/Users/wuyoscar/Downloads/exmaple.flac'

# Read audio data and sample rate from the FLAC file using the soundfile library
audio_flac, sample_rate_flac = sf.read(media_file_name_flac)

# Get the number of audio channels from the FLAC file using the soundfile library
flac_info = sf.info(media_file_name_flac)
num_channels_flac = flac_info.channels

# Read the contents of the FLAC file into a RecognitionAudio object
with open(media_file_name_flac, 'rb') as f:
    audio_flac = speech.RecognitionAudio(content=f.read())

# Read the contents of the MP3 file into a RecognitionAudio object
with open(media_file_name_mp3, 'rb') as f:
    audio_mp3 = speech.RecognitionAudio(content=f.read())

# Set up the recognition config object for the MP3 file with the required parameters
config_mp3 = speech.RecognitionConfig(
    sample_rate_hertz=44100,
    language_code="zh-CN"
)

# Set up the recognition config object for the FLAC file with the correct number of channels and other parameters
config_flac = speech.RecognitionConfig(
    encoding=speech.RecognitionConfig.AudioEncoding.FLAC,
    sample_rate_hertz=sample_rate_flac,
    audio_channel_count=num_channels_flac,
    language_code="cmn-Hans-CN"
)

speech_client.recognize(
    config=config_mp3, 
    audio=audio_mp3
)

</d-code>
</details>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">results</span> <span class="p">{</span>
  <span class="n">alternatives</span> <span class="p">{</span>
    <span class="n">transcript</span><span class="p">:</span> <span class="sh">"</span><span class="s">Hello大家好我叫Oscar,我来自中国重庆很高兴认识大家,在这里希望跟大家开始一段学习旅程</span><span class="sh">"</span>
    <span class="nf">english_script</span><span class="p">(</span><span class="n">self</span><span class="o">-</span><span class="n">added</span><span class="p">):</span> <span class="sh">"</span><span class="s">Hello everyone, my name is Oscar, and I come from Chongqing, China. Nice to meet you, and I hope to start a learning journey with you here</span><span class="sh">""</span><span class="s">
    confidence: 0.950523674
  }
  result_end_time {
    seconds: 13
    nanos: 920000000
  }
  language_code: </span><span class="sh">"</span><span class="n">cmn</span><span class="o">-</span><span class="n">hans</span><span class="o">-</span><span class="n">cn</span><span class="sh">"</span><span class="s">
}
total_billed_time {
  seconds: 14
}
request_id: 5898031208######
</span></code></pre></div></div>

<h3 id="transcribe-the-entire-episode">Transcribe the entire episode</h3>

<p>Now that we have tested the Google Cloud Speech-to-Text API on a short audio clip, we can transcribe the entire episode. To do this, we can use the <code class="language-plaintext highlighter-rouge">transcribe_audio</code> function to transcribe the audio file and save the transcription to a text file. The <code class="language-plaintext highlighter-rouge">transcribe_audio</code> function is as following:</p>

<p>Table below is Reference for selected <a href="https://cloud.google.com/speech-to-text/docs/reference/rpc/google.cloud.speech.v1p1beta1#recognitionconfig">parameters</a> :</p>

<table>
  <thead>
    <tr>
      <th>Name</th>
      <th style="text-align: left">Desc</th>
      <th style="text-align: center">Variable</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">load_custom_phrases</code></td>
      <td style="text-align: left">You can create phrases and store list in yaml file</td>
      <td style="text-align: center">Function</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">create_adaptation_resources</code> (<strong>skip</strong>)</td>
      <td style="text-align: left">By utilizing the model adaptation function, you can specify the words and/or phrases that Speech-to-Text must recognize more frequently in the audio data, without suggesting other potentially suitable alternative expressions.</td>
      <td style="text-align: center">Function</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">upload_blob</code></td>
      <td style="text-align: left">If audio file is more than 1 mins, you need upload to file into <em>Cloud Storage</em></td>
      <td style="text-align: center">Function</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">language_code</code></td>
      <td style="text-align: left"><a href="https://cloud.google.com/speech-to-text/docs/speech-to-text-supported-languages">speech-to-text-supported-languages</a></td>
      <td style="text-align: center">Fcuntion Parameter</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">bucket_name</code></td>
      <td style="text-align: left">Name of the Google Cloud Storage bucket</td>
      <td style="text-align: center">Google Cloud Variable</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">file_path</code></td>
      <td style="text-align: left">Path to the audio file to be transcribed</td>
      <td style="text-align: center">Audio File</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">credentials_path</code></td>
      <td style="text-align: left">path to service account credential</td>
      <td style="text-align: center">Google Cloud Variable</td>
    </tr>
  </tbody>
</table>

<details><summary>Wrap everything together and custmoize configuration based on content</summary>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">google.cloud</span> <span class="kn">import</span> <span class="n">speech_v1p1beta1</span> <span class="k">as</span> <span class="n">speech</span>
<span class="kn">from</span> <span class="n">google.cloud</span> <span class="kn">import</span> <span class="n">storage</span>
<span class="kn">import</span> <span class="n">os</span>
<span class="kn">import</span> <span class="n">yaml</span>

<span class="n">credentials_path</span> <span class="o">=</span> <span class="sh">"</span><span class="s">path/to/your/credentials.json</span><span class="sh">"</span>
<span class="n">os</span><span class="p">.</span><span class="n">environ</span><span class="p">[</span><span class="sh">'</span><span class="s">GOOGLE_APPLICATION_CREDENTIALS</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">credentials_path</span>

<span class="n">load_custom_phrases_path</span> <span class="o">=</span> <span class="sh">'</span><span class="s">path/to/your/custom_phrases.yaml</span><span class="sh">'</span>
<span class="n">project_id</span> <span class="o">=</span> <span class="sh">"</span><span class="s">your-project-id</span><span class="sh">"</span>
<span class="n">location</span> <span class="o">=</span> <span class="sh">"</span><span class="s">global</span><span class="sh">"</span>
<span class="n">custom_class_id</span> <span class="o">=</span> <span class="sh">"</span><span class="s">mycustomclass01</span><span class="sh">"</span>
<span class="n">phrase_set_id</span> <span class="o">=</span> <span class="sh">"</span><span class="s">myphraseset01</span><span class="sh">"</span>


<span class="k">def</span> <span class="nf">load_custom_phrases</span><span class="p">(</span><span class="n">file_path</span><span class="o">=</span><span class="n">load_custom_phrases_path</span><span class="p">):</span>
    <span class="k">with</span> <span class="nf">open</span><span class="p">(</span><span class="n">file_path</span><span class="p">,</span> <span class="sh">'</span><span class="s">r</span><span class="sh">'</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="sh">'</span><span class="s">utf-8</span><span class="sh">'</span><span class="p">)</span> <span class="k">as</span> <span class="nb">file</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">yaml</span><span class="p">.</span><span class="nf">safe_load</span><span class="p">(</span><span class="nb">file</span><span class="p">)</span>



<span class="k">def</span> <span class="nf">upload_blob</span><span class="p">(</span><span class="n">bucket_name</span><span class="p">,</span> <span class="n">source_file_name</span><span class="p">,</span> <span class="n">destination_blob_name</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">Uploads a file to the bucket.</span><span class="sh">"""</span>
    <span class="n">storage_client</span> <span class="o">=</span> <span class="n">storage</span><span class="p">.</span><span class="n">Client</span><span class="p">.</span><span class="nf">from_service_account_json</span><span class="p">(</span><span class="n">credentials_path</span><span class="p">)</span>
    <span class="n">bucket</span> <span class="o">=</span> <span class="n">storage_client</span><span class="p">.</span><span class="nf">get_bucket</span><span class="p">(</span><span class="n">bucket_name</span><span class="p">)</span>
    <span class="n">blob</span> <span class="o">=</span> <span class="n">bucket</span><span class="p">.</span><span class="nf">blob</span><span class="p">(</span><span class="n">destination_blob_name</span><span class="p">)</span>

    <span class="n">blob</span><span class="p">.</span><span class="nf">upload_from_filename</span><span class="p">(</span><span class="n">source_file_name</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">File </span><span class="si">{</span><span class="n">source_file_name</span><span class="si">}</span><span class="s"> uploaded to </span><span class="si">{</span><span class="n">destination_blob_name</span><span class="si">}</span><span class="s">.</span><span class="sh">"</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">transcribe_audio_file</span><span class="p">(</span><span class="n">bucket_name</span><span class="p">,</span> <span class="n">file_path</span><span class="p">,</span> <span class="n">phrases</span><span class="p">):</span>
    <span class="n">destination_blob_name</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="nf">basename</span><span class="p">(</span><span class="n">file_path</span><span class="p">)</span>
    <span class="n">storage_client</span> <span class="o">=</span> <span class="n">storage</span><span class="p">.</span><span class="n">Client</span><span class="p">.</span><span class="nf">from_service_account_json</span><span class="p">(</span><span class="n">credentials_path</span><span class="p">)</span>
    <span class="n">bucket</span> <span class="o">=</span> <span class="n">storage_client</span><span class="p">.</span><span class="nf">get_bucket</span><span class="p">(</span><span class="n">bucket_name</span><span class="p">)</span>
    <span class="n">blob</span> <span class="o">=</span> <span class="n">bucket</span><span class="p">.</span><span class="nf">blob</span><span class="p">(</span><span class="n">destination_blob_name</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">blob</span><span class="p">.</span><span class="nf">exists</span><span class="p">():</span>
        <span class="nf">upload_blob</span><span class="p">(</span><span class="n">bucket_name</span><span class="p">,</span> <span class="n">file_path</span><span class="p">,</span> <span class="n">destination_blob_name</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">File </span><span class="si">{</span><span class="n">destination_blob_name</span><span class="si">}</span><span class="s"> already exists in the bucket.</span><span class="sh">"</span><span class="p">)</span>

    <span class="n">client</span> <span class="o">=</span> <span class="n">speech</span><span class="p">.</span><span class="n">SpeechClient</span><span class="p">.</span><span class="nf">from_service_account_json</span><span class="p">(</span><span class="n">credentials_path</span><span class="p">)</span>

    <span class="n">config</span> <span class="o">=</span> <span class="n">speech</span><span class="p">.</span><span class="nc">RecognitionConfig</span><span class="p">(</span>
        <span class="n">encoding</span><span class="o">=</span><span class="n">speech</span><span class="p">.</span><span class="n">RecognitionConfig</span><span class="p">.</span><span class="n">AudioEncoding</span><span class="p">.</span><span class="n">MP3</span><span class="p">,</span>
        <span class="n">sample_rate_hertz</span><span class="o">=</span><span class="mi">44100</span><span class="p">,</span>
        <span class="n">audio_channel_count</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
        <span class="n">language_code</span><span class="o">=</span><span class="sh">"</span><span class="s">zh-CN</span><span class="sh">"</span><span class="p">,</span>
        <span class="n">enable_automatic_punctuation</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
        <span class="n">enable_separate_recognition_per_channel</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
        <span class="n">use_enhanced</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
        <span class="n">enable_speaker_diarization</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
        <span class="n">diarization_speaker_count</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
        <span class="n">speech_contexts</span><span class="o">=</span><span class="p">[{</span><span class="sh">"</span><span class="s">phrases</span><span class="sh">"</span><span class="p">:</span> <span class="n">phrases</span><span class="p">}],</span>
    <span class="p">)</span>

    <span class="n">storage_uri</span> <span class="o">=</span> <span class="sa">f</span><span class="sh">"</span><span class="s">gs://</span><span class="si">{</span><span class="n">bucket_name</span><span class="si">}</span><span class="s">/</span><span class="si">{</span><span class="n">destination_blob_name</span><span class="si">}</span><span class="sh">"</span>
    <span class="n">audio</span> <span class="o">=</span> <span class="n">speech</span><span class="p">.</span><span class="nc">RecognitionAudio</span><span class="p">(</span><span class="n">uri</span><span class="o">=</span><span class="n">storage_uri</span><span class="p">)</span>

    <span class="n">operation</span> <span class="o">=</span> <span class="n">client</span><span class="p">.</span><span class="nf">long_running_recognize</span><span class="p">(</span><span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">,</span> <span class="n">audio</span><span class="o">=</span><span class="n">audio</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Waiting for operation to complete</span><span class="gp">...</span><span class="sh">"</span><span class="s">)

    timeout_seconds = 7200
    response = operation.result(timeout=timeout_seconds)
    return response

def save_response_to_file(response, output_file):
    with open(output_file, </span><span class="sh">'</span><span class="s">w</span><span class="sh">'</span><span class="s">, encoding=</span><span class="sh">'</span><span class="s">utf-8</span><span class="sh">'</span><span class="s">) as f:
        for index, result in enumerate(response.results):
            # Choose the first alternative (most likely) from the list of alternatives
            alternative = result.alternatives[0]
            transcript = alternative.transcript
             #skip empty string and only save the frist transcript
            if transcript.strip() and index % 2 != 0 :
                print(transcript.strip())
                f.write(transcript + </span><span class="sh">'</span><span class="se">\n</span><span class="sh">'</span><span class="s">)
    print(f</span><span class="sh">"</span><span class="n">Transcript</span> <span class="n">saved</span> <span class="n">to</span> <span class="p">{</span><span class="n">output_file</span><span class="p">}</span><span class="sh">"</span><span class="s">)

</span></code></pre></div></div>
</details>

<h2 id="validating-the-transcription-results-via-chatgpt-4-modwel">Validating the Transcription Results via ChatGPT-4 Modwel</h2>
<p>After successfully transcribing the audio content of the “Stochastic Volatility” podcast into text using a speech-to-text API, we need to preprocess the text data. This step is crucial because it helps clean up and format the raw text, allowing our machine learning model to understand and process the content more effectively.</p>

<p>However, upon examining the transcribed text, I noticed two major inaccuracies:</p>

<ol>
  <li>In this text snippet, the names “服饰演”, “张知其”, and “冷见过” were incorrectly recognized. The correct names should be “傅适野”, “张之琪”, and “冷建国”.
    <div class="language-text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>各位听众朋友大家好，欢迎收听星期的随机波动，我是服饰演我是张知其我是冷见过你怎么还吃
</code></pre></div>    </div>
  </li>
  <li>The Chinese text segmentation is not very accurate, leading to missing periods and commas, which makes the sentence meaning unclear.
    <div class="language-text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>...精神上已经就是不是特别稳定了，就是中中间经历了崩。会大哭这样的一个过程
</code></pre></div>    </div>
  </li>
  <li>The text has issues with Chinese punctuation, such as missing periods and commas, which affect the clarity and readability of the content.</li>
</ol>

<p>To address these issues, we can use ChatGPT, a deep learning model, to correct the recognition errors, add missing punctuation, and improve the overall quality of the text. Although many pre-trained models can perform these tasks, they are mostly designed for English text. In this case, we’ll use ChatGPT, which can also handle Chinese text</p>

<h3 id="constructing-useful-prompt">Constructing useful Prompt</h3>
<p>In your correct_text function, you are using ChatGPT to correct grammar errors, add punctuation, and fix recognition errors in the given Chinese text. The function takes the transcribed text as input, sends it to the ChatGPT API along with a prompt that explains the task, and then returns the corrected and punctuated text.</p>

<h4 id="system-message">System message:</h4>
<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="nl">"role"</span><span class="p">:</span><span class="w"> </span><span class="s2">"system"</span><span class="p">,</span><span class="w"> </span><span class="nl">"content"</span><span class="p">:</span><span class="w"> </span><span class="s2">"You are a helpful assistant that corrects grammar errors, adds punctuation, and fixes recognition errors in Chinese text."</span><span class="p">}</span><span class="w">
</span></code></pre></div></div>
<p>This message sets the context for the ChatGPT model, informing it that its role is to be a helpful assistant, responsible for correcting grammar errors, adding punctuation, and fixing recognition errors in the Chinese text.</p>
<h4 id="user-message-background-information">User message (background information):</h4>
<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="nl">"role"</span><span class="p">:</span><span class="w"> </span><span class="s2">"user"</span><span class="p">,</span><span class="w"> </span><span class="nl">"content"</span><span class="p">:</span><span class="w"> </span><span class="s2">"This text is from a cross-cultural podcast initiated by three female media professionals."</span><span class="p">}</span><span class="w">

</span></code></pre></div></div>
<p>This message provides the model with background information about the input text. By mentioning that the text comes from a cross-cultural podcast initiated by three female media professionals, you give the model additional context that might help improve the quality of the generated corrections and adjustments.</p>

<h4 id="user-message-task-instructions">User message (task instructions):</h4>
<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="nl">"role"</span><span class="p">:</span><span class="w"> </span><span class="s2">"user"</span><span class="p">,</span><span class="w"> </span><span class="nl">"content"</span><span class="p">:</span><span class="w"> </span><span class="err">f</span><span class="s2">"Please correct any grammar errors, add punctuation, and fix the recognition errors in the following Chinese text:</span><span class="se">\n</span><span class="s2">{text}</span><span class="se">\n\n</span><span class="s2">For example, the host name is '傅适野，张之琪，冷建国', and there might be missing punctuation like commas and periods. Make the text clear and easy to understand."</span><span class="p">}</span><span class="w">
</span></code></pre></div></div>

<p>This message gives specific instructions for the task. It asks the model to correct grammar errors, add punctuation, and fix recognition errors in the input text. It also provides an example of correctly recognized host names and mentions possible issues with missing punctuation like commas and periods. This helps the model understand the desired output and ensures that the text is clear and easy to understand after the corrections are made.</p>

<h4 id="corrected-text">Corrected Text</h4>
<p>If we check the result from ChatGPT4, we can see the sentence:</p>
<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">
    </span><span class="nl">"before_corrected"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
        </span><span class="nl">"chinese"</span><span class="p">:</span><span class="w"> </span><span class="s2">"我们做这一期节目前就是我们三个因为最近各种新闻确实就是精神状况都觉得有点看特别需问好了"</span><span class="p">,</span><span class="w">
        </span><span class="nl">"english"</span><span class="p">:</span><span class="w"> </span><span class="s2">"We did this episode just the three of us because recently all kinds of news really made our mental states feel a bit particularly in need of asking if we are okay."</span><span class="w">
    </span><span class="p">}</span><span class="w">
</span><span class="p">}</span><span class="w">

</span></code></pre></div></div>

<p>that has been successfully corrected to:</p>

<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">
    </span><span class="nl">"after_corrected"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
        </span><span class="nl">"chinese"</span><span class="p">:</span><span class="w"> </span><span class="s2">"我们做这一期节目前，就是我们三个，傅适野、张之琪、冷建国，因为最近各种新闻确实就是精神状况都觉得有点看特别需问好了。"</span><span class="p">,</span><span class="w">
        </span><span class="nl">"english"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Before we did this episode, it was just the three of us, Fu Shiye, Zhang Zhiqi, and Leng Jianguo, because recently all kinds of news really made our mental states feel a bit particularly in need of asking if we are okay."</span><span class="w">
    </span><span class="p">}</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div>

<details><summary>The complete code for ChatGPT</summary>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">json</span>
<span class="kn">import</span> <span class="n">string</span>
<span class="kn">from</span> <span class="n">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>
<span class="kn">import</span> <span class="n">openai</span>
<span class="kn">import</span> <span class="n">jieba</span>
<span class="kn">from</span> <span class="n">dotenv</span> <span class="kn">import</span> <span class="n">load_dotenv</span>
<span class="kn">import</span> <span class="n">os</span>
<span class="kn">import</span> <span class="n">tiktoken</span>
<span class="kn">import</span> <span class="n">logging</span>
<span class="kn">import</span> <span class="n">time</span>
<span class="kn">from</span> <span class="n">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>
<span class="kn">from</span> <span class="n">tenacity</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">retry</span><span class="p">,</span>
    <span class="n">stop_after_attempt</span><span class="p">,</span>
    <span class="n">wait_random_exponential</span><span class="p">,</span>
<span class="p">)</span>


<span class="c1"># Set up logging
</span><span class="n">logging</span><span class="p">.</span><span class="nf">basicConfig</span><span class="p">(</span><span class="n">level</span><span class="o">=</span><span class="n">logging</span><span class="p">.</span><span class="n">DEBUG</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="sh">'</span><span class="s">%(asctime)s [%(levelname)s] - %(message)s</span><span class="sh">'</span><span class="p">)</span>
<span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="p">.</span><span class="nf">getLogger</span><span class="p">(</span><span class="n">__name__</span><span class="p">)</span>


<span class="c1"># Define paths variables
</span><span class="n">current_path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">.</span><span class="nf">cwd</span><span class="p">()</span>
<span class="n">main_path</span> <span class="o">=</span> <span class="n">current_path</span><span class="p">.</span><span class="n">parent</span>
<span class="n">data_path</span> <span class="o">=</span> <span class="n">main_path</span> <span class="o">/</span> <span class="sh">"</span><span class="s">data</span><span class="sh">"</span>
<span class="n">env_path</span> <span class="o">=</span> <span class="n">main_path</span> <span class="o">/</span> <span class="sh">"</span><span class="s">.env</span><span class="sh">"</span>

<span class="c1"># Load environment variables from .env file
</span><span class="nf">load_dotenv</span><span class="p">(</span><span class="n">env_path</span><span class="p">)</span>

<span class="c1"># Get OpenAI API key from environment variables
</span><span class="n">openai_api_key</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="nf">getenv</span><span class="p">(</span><span class="sh">"</span><span class="s">OPENAI_API_KEY</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># Use OpenAI API key to authenticate with OpenAI
</span><span class="n">openai</span><span class="p">.</span><span class="n">api_key</span> <span class="o">=</span> <span class="n">openai_api_key</span>

<span class="c1"># Define punctuation sets
</span><span class="n">chinese_punctuation</span> <span class="o">=</span> <span class="nf">set</span><span class="p">(</span><span class="sh">"</span><span class="s">。，！？【】（）&lt;&gt;《》“”‘’；：——…～·</span><span class="sh">"</span><span class="p">)</span>
<span class="n">english_punctuation</span> <span class="o">=</span> <span class="nf">set</span><span class="p">(</span><span class="n">string</span><span class="p">.</span><span class="n">punctuation</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">read_file_contents</span><span class="p">(</span><span class="n">file_path</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">Read a text or JSON file and return its contents as a string or dictionary.</span><span class="sh">"""</span>
    <span class="n">file_path</span> <span class="o">=</span> <span class="nc">Path</span><span class="p">(</span><span class="n">file_path</span><span class="p">)</span>
    <span class="n">logger</span><span class="p">.</span><span class="nf">debug</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Reading file </span><span class="si">{</span><span class="n">file_path</span><span class="p">.</span><span class="n">name</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
    <span class="k">with</span> <span class="nf">open</span><span class="p">(</span><span class="n">file_path</span><span class="p">,</span> <span class="sh">"</span><span class="s">r</span><span class="sh">"</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="sh">"</span><span class="s">utf-8</span><span class="sh">"</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">file_path</span><span class="p">.</span><span class="n">suffix</span> <span class="o">==</span> <span class="sh">"</span><span class="s">.txt</span><span class="sh">"</span><span class="p">:</span>
            <span class="n">contents</span> <span class="o">=</span> <span class="n">f</span><span class="p">.</span><span class="nf">read</span><span class="p">().</span><span class="nf">replace</span><span class="p">(</span><span class="sh">"</span><span class="se">\n</span><span class="sh">"</span><span class="p">,</span> <span class="sh">""</span><span class="p">).</span><span class="nf">replace</span><span class="p">(</span><span class="sh">"</span><span class="s"> </span><span class="sh">"</span><span class="p">,</span> <span class="sh">""</span><span class="p">)</span> <span class="c1"># read the contents of a text file and remove newlines and spaces
</span>        <span class="k">elif</span> <span class="n">file_path</span><span class="p">.</span><span class="n">suffix</span> <span class="o">==</span> <span class="sh">"</span><span class="s">.json</span><span class="sh">"</span><span class="p">:</span>
            <span class="n">contents</span> <span class="o">=</span> <span class="n">json</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span> <span class="c1"># read the contents of a JSON file
</span>        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="nc">ValueError</span><span class="p">(</span><span class="sh">"</span><span class="s">File type not supported. Only .txt and .json files are supported.</span><span class="sh">"</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">contents</span>

<span class="k">def</span> <span class="nf">save_result</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="n">file_path</span><span class="p">,</span> <span class="n">line_length</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">50</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">Save the result as a plain text file with no more than 20 characters per line.</span><span class="sh">"""</span>
    <span class="k">with</span> <span class="nf">open</span><span class="p">(</span><span class="n">file_path</span><span class="p">,</span> <span class="sh">"</span><span class="s">w</span><span class="sh">"</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="sh">"</span><span class="s">utf-8</span><span class="sh">"</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nf">len</span><span class="p">(</span><span class="n">result</span><span class="p">),</span> <span class="n">line_length</span><span class="p">):</span>
            <span class="n">line</span> <span class="o">=</span> <span class="n">result</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="n">line_length</span><span class="p">]</span>
            <span class="n">f</span><span class="p">.</span><span class="nf">write</span><span class="p">(</span><span class="n">line</span> <span class="o">+</span> <span class="sh">"</span><span class="se">\n</span><span class="sh">"</span><span class="p">)</span>




<span class="k">def</span> <span class="nf">num_tokens_from_string</span><span class="p">(</span><span class="n">string</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">encoding_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="sh">'</span><span class="s">cl100k_base</span><span class="sh">'</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">Returns the number of tokens in a text string.</span><span class="sh">"""</span>
    <span class="n">encoding</span> <span class="o">=</span> <span class="n">tiktoken</span><span class="p">.</span><span class="nf">get_encoding</span><span class="p">(</span><span class="n">encoding_name</span><span class="p">)</span>
    <span class="n">num_tokens</span> <span class="o">=</span> <span class="nf">len</span><span class="p">(</span><span class="n">encoding</span><span class="p">.</span><span class="nf">encode</span><span class="p">(</span><span class="n">string</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">num_tokens</span>



<span class="nd">@retry</span><span class="p">(</span><span class="n">wait</span><span class="o">=</span><span class="nf">wait_random_exponential</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">60</span><span class="p">),</span> <span class="n">stop</span><span class="o">=</span><span class="nf">stop_after_attempt</span><span class="p">(</span><span class="mi">6</span><span class="p">))</span>
<span class="k">def</span> <span class="nf">completion_with_backoff</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">openai</span><span class="p">.</span><span class="n">ChatCompletion</span><span class="p">.</span><span class="nf">create</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>



<span class="k">def</span> <span class="nf">correct_text_file</span><span class="p">(</span><span class="n">file_path</span><span class="p">,</span> <span class="n">buffer_tokens</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span>  <span class="n">save_corrected_file</span><span class="p">:</span><span class="nb">bool</span><span class="o">=</span><span class="bp">True</span> <span class="p">,</span> <span class="n">model_token_limit</span><span class="p">:</span><span class="nb">int</span><span class="o">=</span><span class="mi">8192</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    <span class="n">text_file</span> <span class="o">=</span> <span class="nc">Path</span><span class="p">(</span><span class="n">file_path</span><span class="p">)</span>

    <span class="n">logger</span><span class="p">.</span><span class="nf">debug</span><span class="p">(</span><span class="sh">"</span><span class="s">Wait for 2 seconds before the next request to OpenAI API</span><span class="sh">"</span><span class="p">)</span>
    <span class="n">time</span><span class="p">.</span><span class="nf">sleep</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>

    <span class="n">text</span> <span class="o">=</span> <span class="nf">read_file_contents</span><span class="p">(</span><span class="n">text_file</span><span class="p">)</span>
    <span class="n">logger</span><span class="p">.</span><span class="nf">debug</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Successfully reading text from </span><span class="si">{</span><span class="n">text_file</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>

    <span class="n">messages</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">{</span><span class="sh">"</span><span class="s">role</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">system</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">content</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">You are a helpful assistant that corrects grammar, punctuation, and recognition errors in Chinese text.</span><span class="sh">"</span><span class="p">},</span>
        <span class="p">{</span><span class="sh">"</span><span class="s">role</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">user</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">content</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">This text is from a podcast by </span><span class="sh">'</span><span class="s">傅适野，张之琪，冷建国</span><span class="sh">'</span><span class="s">. There might be missing punctuation, wrong words, and typos.</span><span class="sh">"</span><span class="p">},</span>
        <span class="p">{</span><span class="sh">"</span><span class="s">role</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">user</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">content</span><span class="sh">"</span><span class="p">:</span> <span class="sa">f</span><span class="sh">"</span><span class="s">Please correct any errors in the following Chinese text based on context and only return corrected text:</span><span class="se">\n</span><span class="si">{</span><span class="n">text</span><span class="si">}</span><span class="sh">"</span><span class="p">},</span>
    <span class="p">]</span>
    
    <span class="c1">## Calculate the number of tokens based on the messages list
</span>
    <span class="n">num_tokens</span> <span class="o">=</span> <span class="nf">num_tokens_from_string</span><span class="p">(</span><span class="sh">'</span><span class="s"> </span><span class="sh">'</span><span class="p">.</span><span class="nf">join</span><span class="p">([</span><span class="n">message</span><span class="p">[</span><span class="sh">'</span><span class="s">content</span><span class="sh">'</span><span class="p">]</span> <span class="k">for</span> <span class="n">message</span> <span class="ow">in</span> <span class="n">messages</span><span class="p">]))</span>
    <span class="n">generated_text_token</span> <span class="o">=</span> <span class="n">num_tokens</span> <span class="o">+</span> <span class="n">buffer_tokens</span>
    <span class="n">logger</span><span class="p">.</span><span class="nf">debug</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Input text tokens: </span><span class="si">{</span><span class="n">num_tokens</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
    <span class="n">logger</span><span class="p">.</span><span class="nf">debug</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Max generated tokens set as </span><span class="si">{</span><span class="n">generated_text_token</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
    <span class="c1">#check token limit
</span>    <span class="nf">if </span><span class="p">(</span><span class="n">generated_text_token</span> <span class="o">+</span> <span class="n">num_tokens</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">model_token_limit</span><span class="p">:</span>
        <span class="n">logger</span><span class="p">.</span><span class="nf">debug</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Token limit exceeded. Please reduce the number of tokens to below </span><span class="si">{</span><span class="n">model_token_limit</span><span class="si">}</span><span class="s">.</span><span class="sh">"</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">None</span>

    <span class="n">response</span> <span class="o">=</span> <span class="nf">completion_with_backoff</span><span class="p">(</span>
        <span class="n">model</span><span class="o">=</span><span class="sh">"</span><span class="s">gpt-4-0314</span><span class="sh">"</span><span class="p">,</span>
        <span class="n">messages</span><span class="o">=</span><span class="n">messages</span><span class="p">,</span>
        <span class="n">max_tokens</span><span class="o">=</span><span class="n">generated_text_token</span>
    <span class="p">)</span>
    <span class="n">generated_text</span> <span class="o">=</span> <span class="n">response</span><span class="p">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="sh">"</span><span class="s">message</span><span class="sh">"</span><span class="p">][</span><span class="sh">'</span><span class="s">content</span><span class="sh">'</span><span class="p">]</span>
    <span class="n">generated_text</span> <span class="o">=</span> <span class="n">generated_text</span><span class="p">.</span><span class="nf">strip</span><span class="p">()</span>

    
    <span class="k">if</span> <span class="n">save_corrected_file</span><span class="p">:</span>
        <span class="n">result_file_path</span> <span class="o">=</span> <span class="n">text_file</span><span class="p">.</span><span class="nf">with_name</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">text_file</span><span class="p">.</span><span class="n">stem</span><span class="si">}</span><span class="s">_restoration.txt</span><span class="sh">"</span><span class="p">)</span>
        <span class="nf">save_result</span><span class="p">(</span><span class="n">generated_text</span><span class="p">,</span> <span class="n">result_file_path</span><span class="p">)</span>
        <span class="n">logger</span><span class="p">.</span><span class="nf">debug</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Successfully writing result to </span><span class="si">{</span><span class="n">result_file_path</span><span class="p">.</span><span class="n">name</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>

    <span class="n">logger</span><span class="p">.</span><span class="nf">debug</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Successfully processing text from </span><span class="si">{</span><span class="n">text_file</span><span class="p">.</span><span class="n">name</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">generated_text</span>
 
    
<span class="k">def</span> <span class="nf">text_restoration</span><span class="p">(</span><span class="n">filename</span> <span class="p">,</span><span class="n">chunk_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">600</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">Tokenize Chinese text using jieba, remove punctuation, and write each chunk to a separate file.</span><span class="sh">"""</span>
    <span class="n">filename</span> <span class="o">=</span> <span class="nc">Path</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span>
    <span class="n">content</span> <span class="o">=</span> <span class="nf">read_file_contents</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span>
    <span class="c1">#remove all punctuation    
</span>    <span class="n">tokens</span> <span class="o">=</span> <span class="p">[</span><span class="n">token</span><span class="p">.</span><span class="nf">strip</span><span class="p">()</span> <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">jieba</span><span class="p">.</span><span class="nf">cut</span><span class="p">(</span><span class="n">content</span><span class="p">,</span> <span class="n">cut_all</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span> <span class="k">if</span> <span class="n">token</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">chinese_punctuation</span> <span class="ow">and</span> <span class="n">token</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">english_punctuation</span><span class="p">]</span>
    <span class="n">restoration_text</span> <span class="o">=</span> <span class="sh">""</span><span class="p">.</span><span class="nf">join</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>
    <span class="n">tokens_res</span> <span class="o">=</span> <span class="n">jieba</span><span class="p">.</span><span class="nf">lcut</span><span class="p">(</span><span class="n">restoration_text</span><span class="p">)</span>
    
    <span class="c1">#split into chunks
</span>    <span class="n">chunks</span> <span class="o">=</span> <span class="p">[</span><span class="n">tokens_res</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="n">chunk_size</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nf">len</span><span class="p">(</span><span class="n">tokens_res</span><span class="p">),</span> <span class="n">chunk_size</span><span class="p">)]</span>
    <span class="n">logger</span><span class="p">.</span><span class="nf">debug</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Splitting </span><span class="si">{</span><span class="n">filename</span><span class="p">.</span><span class="n">name</span><span class="si">}</span><span class="s"> into </span><span class="si">{</span><span class="nf">len</span><span class="p">(</span><span class="n">chunks</span><span class="p">)</span><span class="si">}</span><span class="s"> chunks</span><span class="sh">"</span><span class="p">)</span>
    
    <span class="c1"># Create the output directory if it doesn't exist
</span>    <span class="n">output_dir</span> <span class="o">=</span> <span class="n">data_path</span> <span class="o">/</span> <span class="n">filename</span><span class="p">.</span><span class="n">stem</span>
    <span class="nc">Path</span><span class="p">(</span><span class="n">output_dir</span><span class="p">).</span><span class="nf">mkdir</span><span class="p">(</span><span class="n">exist_ok</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">file_stem</span> <span class="o">=</span> <span class="n">filename</span><span class="p">.</span><span class="n">stem</span>
    
    <span class="c1"># Write each chunk to a separate file
</span>    <span class="n">corrected_texts</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">chunks</span><span class="p">):</span>
        <span class="n">chunk_text</span> <span class="o">=</span> <span class="sh">""</span><span class="p">.</span><span class="nf">join</span><span class="p">(</span><span class="n">chunk</span><span class="p">)</span>
        <span class="n">chunk_filename</span> <span class="o">=</span> <span class="n">output_dir</span><span class="o">/</span><span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">file_stem</span><span class="si">}</span><span class="s">_chunk_</span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s">.txt</span><span class="sh">"</span>
        
        <span class="n">logger</span><span class="p">.</span><span class="nf">debug</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Writing chunk </span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s"> to </span><span class="si">{</span><span class="n">chunk_filename</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
        
        <span class="nf">save_result</span><span class="p">(</span><span class="n">chunk_text</span><span class="p">,</span> <span class="n">chunk_filename</span><span class="p">)</span>
        
        <span class="n">generated_text</span> <span class="o">=</span> <span class="nf">correct_text_file</span><span class="p">(</span><span class="n">chunk_filename</span><span class="p">,</span> <span class="n">save_corrected_file</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">corrected_texts</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">generated_text</span><span class="p">)</span>
    
    <span class="n">combined_corrected_text</span> <span class="o">=</span> <span class="sh">"</span><span class="se">\n</span><span class="sh">"</span><span class="p">.</span><span class="nf">join</span><span class="p">(</span><span class="n">corrected_texts</span><span class="p">)</span>
    <span class="n">combined_corrected_text</span> <span class="o">=</span> <span class="n">combined_corrected_text</span><span class="p">.</span><span class="nf">replace</span><span class="p">(</span><span class="sh">"</span><span class="se">\n</span><span class="sh">"</span><span class="p">,</span> <span class="sh">""</span><span class="p">)</span>  <span class="c1"># remove all newlines
</span>    <span class="c1"># remove all unnecessary spaces
</span>    <span class="n">combined_corrected_text</span> <span class="o">=</span> <span class="sh">'</span><span class="s"> </span><span class="sh">'</span><span class="p">.</span><span class="nf">join</span><span class="p">(</span><span class="n">combined_corrected_text</span><span class="p">.</span><span class="nf">split</span><span class="p">())</span>

    <span class="n">combined_file_path</span> <span class="o">=</span> <span class="sa">f</span><span class="sh">"</span><span class="s">output_dir / </span><span class="si">{</span><span class="n">file_stem</span><span class="si">}</span><span class="s">_restoration.txt</span><span class="sh">"</span>
    <span class="nf">save_result</span><span class="p">(</span><span class="n">combined_corrected_text</span><span class="p">,</span> <span class="n">combined_file_path</span><span class="p">)</span>
    


<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="sh">"</span><span class="s">__main__</span><span class="sh">"</span><span class="p">:</span>

    <span class="n">filename</span> <span class="o">=</span> <span class="sh">""</span>
    <span class="nf">text_restoration</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">chunk_size</span><span class="o">=</span><span class="mi">700</span><span class="p">)</span>
</code></pre></div></div>
</details>

<h2 id="preprocessing-the-chinese-text-data">Preprocessing the Chinese Text Data</h2>
<p>In this section, we will cover the following preprocessing techniques:</p>
<ol>
  <li>Tokenization</li>
  <li>Removing stop words</li>
  <li>Removing special characters and numbers</li>
  <li>Lowercasing</li>
  <li>Lemmatization</li>
</ol>

<h3 id="tokenization">Tokenization</h3>
<p>Tokenization is the process of breaking down the text into individual words or tokens. For Chinese text, we will use the Jieba library for tokenization.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">jieba</span>
<span class="k">def</span> <span class="nf">tokenize_chinese_text</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="n">tokens</span> <span class="o">=</span> <span class="n">jieba</span><span class="p">.</span><span class="nf">lcut</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">tokens</span>

</code></pre></div></div>

<h3 id="removing-stop-words">Removing stop words</h3>
<p>Stop words are common words that do not carry much meaning and can be removed from the text to reduce noise. You can either create a custom list of Chinese stop words or find an existing list online. Load the stop words into a Python set for efficient filtering. Here we will use the stop words list from <a href="https://raw.githubusercontent.com/goto456/stopwords/master/hit_stopwords.txt">hit_stopwords</a></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">requests</span>

<span class="n">url</span> <span class="o">=</span> <span class="sh">'</span><span class="s">https://raw.githubusercontent.com/goto456/stopwords/master/hit_stopwords.txt</span><span class="sh">'</span>
<span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
<span class="n">stopwords</span> <span class="o">=</span> <span class="n">response</span><span class="p">.</span><span class="n">text</span><span class="p">.</span><span class="nf">split</span><span class="p">(</span><span class="sh">'</span><span class="se">\n</span><span class="sh">'</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">remove_stop_words</span><span class="p">(</span><span class="n">tokens</span><span class="p">,</span> <span class="n">stop_words</span><span class="p">):</span>
    <span class="n">cleaned_tokens</span> <span class="o">=</span> <span class="p">[</span><span class="n">word</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">tokens</span> <span class="k">if</span> <span class="n">word</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">stop_words</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">cleaned_tokens</span>

</code></pre></div></div>

<h3 id="removing-special-characters-and-numbers">Removing special characters and numbers</h3>
<p>We will remove any special characters, numbers, and whitespace from the tokens to further clean the text.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">remove_special_characters_and_numbers</span><span class="p">(</span><span class="n">tokens</span><span class="p">):</span>
    <span class="n">cleaned_tokens</span> <span class="o">=</span> <span class="p">[</span><span class="n">word</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">tokens</span> <span class="k">if</span> <span class="n">word</span><span class="p">.</span><span class="nf">strip</span><span class="p">()</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">word</span><span class="p">.</span><span class="nf">isdigit</span><span class="p">()]</span>
    <span class="k">return</span> <span class="n">cleaned_tokens</span>
</code></pre></div></div>

<h3 id="preprocessing-pipeline">Preprocessing Pipeline</h3>
<p>Now, we will create a preprocessing pipeline that combines all the above techniques. The pipeline takes raw Chinese text as input and returns cleaned tokens.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">requests</span>

<span class="n">url</span> <span class="o">=</span> <span class="sh">'</span><span class="s">https://raw.githubusercontent.com/goto456/stopwords/master/hit_stopwords.txt</span><span class="sh">'</span>
<span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
<span class="n">stop_words</span> <span class="o">=</span> <span class="n">response</span><span class="p">.</span><span class="n">text</span><span class="p">.</span><span class="nf">split</span><span class="p">(</span><span class="sh">'</span><span class="se">\n</span><span class="sh">'</span><span class="p">)</span>

<span class="kn">import</span> <span class="n">jieba</span>
<span class="k">def</span> <span class="nf">tokenize_chinese_text</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="n">tokens</span> <span class="o">=</span> <span class="n">jieba</span><span class="p">.</span><span class="nf">lcut</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">tokens</span>
<span class="k">def</span> <span class="nf">remove_stop_words</span><span class="p">(</span><span class="n">tokens</span><span class="p">,</span> <span class="n">stop_words</span><span class="p">):</span>
    <span class="n">cleaned_tokens</span> <span class="o">=</span> <span class="p">[</span><span class="n">word</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">tokens</span> <span class="k">if</span> <span class="n">word</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">stop_words</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">cleaned_tokens</span>

<span class="k">def</span> <span class="nf">remove_special_characters_and_numbers</span><span class="p">(</span><span class="n">tokens</span><span class="p">):</span>
    <span class="n">cleaned_tokens</span> <span class="o">=</span> <span class="p">[</span><span class="n">word</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">tokens</span> <span class="k">if</span> <span class="n">word</span><span class="p">.</span><span class="nf">strip</span><span class="p">()</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">word</span><span class="p">.</span><span class="nf">isdigit</span><span class="p">()]</span>
    <span class="k">return</span> <span class="n">cleaned_tokens</span>

<span class="k">def</span> <span class="nf">preprocess_chinese_text</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">stop_words</span><span class="p">):</span>
    <span class="c1"># Tokenize
</span>    <span class="n">tokens</span> <span class="o">=</span> <span class="nf">tokenize_chinese_text</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>

    <span class="c1"># Remove stop words
</span>    <span class="n">tokens</span> <span class="o">=</span> <span class="nf">remove_stop_words</span><span class="p">(</span><span class="n">tokens</span><span class="p">,</span> <span class="n">stop_words</span><span class="p">)</span>

    <span class="c1"># Remove special characters and numbers
</span>    <span class="n">cleaned_tokens</span> <span class="o">=</span> <span class="nf">remove_special_characters_and_numbers</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">cleaned_tokens</span>


<span class="k">with</span> <span class="nf">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="sh">'</span><span class="s">r</span><span class="sh">'</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="sh">'</span><span class="s">utf-8</span><span class="sh">'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
   <span class="n">content</span> <span class="o">=</span> <span class="n">f</span><span class="p">.</span><span class="nf">read</span><span class="p">()</span>
   <span class="n">process_content</span> <span class="o">=</span> <span class="nf">preprocess_chinese_text</span><span class="p">(</span><span class="n">content</span><span class="p">,</span> <span class="n">stop_words</span> <span class="o">=</span> <span class="n">stop_words</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="analyzing-the-text-data">Analyzing the Text Data</h3>

<h3 id="visualizing-the-results">Visualizing the Results</h3>
<blockquote>
  <p>add figure here</p>
</blockquote>

<h3 id="conclusion">Conclusion</h3>
<blockquote>
  <p>write conclusion here</p>
</blockquote>]]></content><author><name>Oscar Wu</name></author><category term="NLP," /><category term="Tools," /><category term="API" /><category term="Speech-to-text," /><category term="Chinese-NLP," /><category term="ChatGPT4," /><category term="NLP," /><category term="Machine" /><category term="Learning," /><category term="ChatGPT" /><summary type="html"><![CDATA[Uncover the power of natural language processing (NLP) and machine learning techniques in analyzing 随机波动 Stochastic Volatility podcasts. Delve into the complete workflow, from data collection and audio transcription to text preprocessing, analysis, and visualization, to gain valuable insights on podcast topics, emotions, and overall content.]]></summary></entry><entry><title type="html">Markdown guide</title><link href="https://wuyoscar.github.io/blog/2023/MarkdownGuide/" rel="alternate" type="text/html" title="Markdown guide" /><published>2023-04-22T00:00:00+00:00</published><updated>2023-04-22T00:00:00+00:00</updated><id>https://wuyoscar.github.io/blog/2023/MarkdownGuide</id><content type="html" xml:base="https://wuyoscar.github.io/blog/2023/MarkdownGuide/"><![CDATA[<h2 id="equations">Equations</h2>

<p>This theme supports rendering beautiful math in inline and display modes using <a href="https://www.mathjax.org/">MathJax 3</a> engine.
You just need to surround your math expression with <code class="language-plaintext highlighter-rouge">$$</code>, like <code class="language-plaintext highlighter-rouge">$$ E = mc^2 $$</code>.
If you leave it inside a paragraph, it will produce an inline expression, just like \(E = mc^2\).</p>

<p>To use display mode, again surround your expression with <code class="language-plaintext highlighter-rouge">$$</code> and place it as a separate paragraph.
Here is an example:</p>

\[\left( \sum_{k=1}^n a_k b_k \right)^2 \leq \left( \sum_{k=1}^n a_k^2 \right) \left( \sum_{k=1}^n b_k^2 \right)\]

<p>Note that MathJax 3 is <a href="https://docs.mathjax.org/en/latest/upgrading/whats-new-3.0.html">a major re-write of MathJax</a> that brought a significant improvement to the loading and rendering speed, which is now <a href="http://www.intmath.com/cg5/katex-mathjax-comparison.php">on par with KaTeX</a>.</p>

<hr />

<h2 id="citations">Citations</h2>

<p>Citations are then used in the article body with the <code class="language-plaintext highlighter-rouge">&lt;d-cite&gt;</code> tag.
The key attribute is a reference to the id provided in the bibliography.
The key attribute can take multiple ids, separated by commas.</p>

<p>The citation is presented inline like this: <d-cite key="gregor2015draw"></d-cite> (a number that displays more information on hover).
If you have an appendix, a bibliography is automatically created and populated in it.</p>

<p>Distill chose a numerical inline citation style to improve readability of citation dense articles and because many of the benefits of longer citations are obviated by displaying more information on hover.
However, we consider it good style to mention author last names if you discuss something at length and it fits into the flow well — the authors are human and it’s nice for them to have the community associate them with their work.</p>

<hr />

<h2 id="footnotes">Footnotes</h2>

<p>Just wrap the text you would like to show up in a footnote in a <code class="language-plaintext highlighter-rouge">&lt;d-footnote&gt;</code> tag.
The number of the footnote will be automatically generated.<d-footnote>This will become a hoverable footnote.</d-footnote></p>

<hr />

<h2 id="code-blocks">Code Blocks</h2>

<p>Syntax highlighting is provided within <code class="language-plaintext highlighter-rouge">&lt;d-code&gt;</code> tags.
An example of inline code snippets: <code class="language-plaintext highlighter-rouge">&lt;d-code language="html"&gt;let x = 10;&lt;/d-code&gt;</code>.
For larger blocks of code, add a <code class="language-plaintext highlighter-rouge">block</code> attribute:</p>

<d-code block="" language="javascript">
  var x = 25;
  function(x) {
    return x * x;
  }
</d-code>

<p><strong>Note:</strong> <code class="language-plaintext highlighter-rouge">&lt;d-code&gt;</code> blocks do not look good in the dark mode.
You can always use the default code-highlight using the <code class="language-plaintext highlighter-rouge">highlight</code> liquid tag:</p>

<figure class="highlight"><pre><code class="language-javascript" data-lang="javascript"><span class="kd">var</span> <span class="nx">x</span> <span class="o">=</span> <span class="mi">25</span><span class="p">;</span>
<span class="kd">function</span><span class="p">(</span><span class="nx">x</span><span class="p">)</span> <span class="p">{</span>
  <span class="k">return</span> <span class="nx">x</span> <span class="o">*</span> <span class="nx">x</span><span class="p">;</span>
<span class="p">}</span></code></pre></figure>

<hr />

<h2 id="interactive-plots">Interactive Plots</h2>

<p>You can add interative plots using plotly + iframes :framed_picture:</p>

<div class="l-page">
  <iframe src="/assets/plotly/demo.html" frameborder="0" scrolling="no" height="500px" width="100%" style="border: 1px dashed grey;"></iframe>
</div>

<p>The plot must be generated separately and saved into an HTML file.
To generate the plot that you see above, you can use the following code snippet:</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="n">plotly.express</span> <span class="k">as</span> <span class="n">px</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span>
  <span class="sh">'</span><span class="s">https://raw.githubusercontent.com/plotly/datasets/master/earthquakes-23k.csv</span><span class="sh">'</span>
<span class="p">)</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">px</span><span class="p">.</span><span class="nf">density_mapbox</span><span class="p">(</span>
  <span class="n">df</span><span class="p">,</span>
  <span class="n">lat</span><span class="o">=</span><span class="sh">'</span><span class="s">Latitude</span><span class="sh">'</span><span class="p">,</span>
  <span class="n">lon</span><span class="o">=</span><span class="sh">'</span><span class="s">Longitude</span><span class="sh">'</span><span class="p">,</span>
  <span class="n">z</span><span class="o">=</span><span class="sh">'</span><span class="s">Magnitude</span><span class="sh">'</span><span class="p">,</span>
  <span class="n">radius</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
  <span class="n">center</span><span class="o">=</span><span class="nf">dict</span><span class="p">(</span><span class="n">lat</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">lon</span><span class="o">=</span><span class="mi">180</span><span class="p">),</span>
  <span class="n">zoom</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
  <span class="n">mapbox_style</span><span class="o">=</span><span class="sh">"</span><span class="s">stamen-terrain</span><span class="sh">"</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">fig</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
<span class="n">fig</span><span class="p">.</span><span class="nf">write_html</span><span class="p">(</span><span class="sh">'</span><span class="s">assets/plotly/demo.html</span><span class="sh">'</span><span class="p">)</span></code></pre></figure>

<hr />

<h2 id="details-boxes">Details boxes</h2>

<p>Details boxes are collapsible boxes which hide additional information from the user. They can be added with the <code class="language-plaintext highlighter-rouge">details</code> liquid tag:</p>

<details><summary>Click here to know more</summary>
<p>Additional details, where math \(2x - 1\) and <code class="language-plaintext highlighter-rouge">code</code> is rendered correctly.</p>
</details>

<hr />

<h2 id="layouts">Layouts</h2>

<p>The main text column is referred to as the body.
It is the assumed layout of any direct descendants of the <code class="language-plaintext highlighter-rouge">d-article</code> element.</p>

<div class="fake-img l-body">
  <p>.l-body</p>
</div>

<p>For images you want to display a little larger, try <code class="language-plaintext highlighter-rouge">.l-page</code>:</p>

<div class="fake-img l-page">
  <p>.l-page</p>
</div>

<p>All of these have an outset variant if you want to poke out from the body text a little bit.
For instance:</p>

<div class="fake-img l-body-outset">
  <p>.l-body-outset</p>
</div>

<div class="fake-img l-page-outset">
  <p>.l-page-outset</p>
</div>

<p>Occasionally you’ll want to use the full browser width.
For this, use <code class="language-plaintext highlighter-rouge">.l-screen</code>.
You can also inset the element a little from the edge of the browser by using the inset variant.</p>

<div class="fake-img l-screen">
  <p>.l-screen</p>
</div>
<div class="fake-img l-screen-inset">
  <p>.l-screen-inset</p>
</div>

<p>The final layout is for marginalia, asides, and footnotes.
It does not interrupt the normal flow of <code class="language-plaintext highlighter-rouge">.l-body</code> sized text except on mobile screen sizes.</p>

<div class="fake-img l-gutter">
  <p>.l-gutter</p>
</div>

<hr />

<h2 id="other-typography">Other Typography?</h2>

<p>Emphasis, aka italics, with <em>asterisks</em> (<code class="language-plaintext highlighter-rouge">*asterisks*</code>) or <em>underscores</em> (<code class="language-plaintext highlighter-rouge">_underscores_</code>).</p>

<p>Strong emphasis, aka bold, with <strong>asterisks</strong> or <strong>underscores</strong>.</p>

<p>Combined emphasis with <strong>asterisks and <em>underscores</em></strong>.</p>

<p>Strikethrough uses two tildes. <del>Scratch this.</del></p>

<ol>
  <li>First ordered list item</li>
  <li>Another item
⋅⋅* Unordered sub-list.</li>
  <li>Actual numbers don’t matter, just that it’s a number
⋅⋅1. Ordered sub-list</li>
  <li>And another item.</li>
</ol>

<p>⋅⋅⋅You can have properly indented paragraphs within list items. Notice the blank line above, and the leading spaces (at least one, but we’ll use three here to also align the raw Markdown).</p>

<p>⋅⋅⋅To have a line break without a paragraph, you will need to use two trailing spaces.⋅⋅
⋅⋅⋅Note that this line is separate, but within the same paragraph.⋅⋅
⋅⋅⋅(This is contrary to the typical GFM line break behaviour, where trailing spaces are not required.)</p>

<ul>
  <li>Unordered list can use asterisks</li>
  <li>Or minuses</li>
  <li>Or pluses</li>
</ul>

<p><a href="https://www.google.com">I’m an inline-style link</a></p>

<p><a href="https://www.google.com" title="Google's Homepage">I’m an inline-style link with title</a></p>

<p><a href="https://www.mozilla.org">I’m a reference-style link</a></p>

<p><a href="../blob/master/LICENSE">I’m a relative reference to a repository file</a></p>

<p><a href="http://slashdot.org">You can use numbers for reference-style link definitions</a></p>

<p>Or leave it empty and use the <a href="http://www.reddit.com">link text itself</a>.</p>

<p>URLs and URLs in angle brackets will automatically get turned into links.
http://www.example.com or <a href="http://www.example.com">http://www.example.com</a> and sometimes
example.com (but not on Github, for example).</p>

<p>Some text to show that the reference links can follow later.</p>

<p>Here’s our logo (hover to see the title text):</p>

<p>Inline-style:
<img src="https://github.com/adam-p/markdown-here/raw/master/src/common/images/icon48.png" alt="alt text" title="Logo Title Text 1" /></p>

<p>Reference-style:
<img src="https://github.com/adam-p/markdown-here/raw/master/src/common/images/icon48.png" alt="alt text" title="Logo Title Text 2" /></p>

<p>Inline <code class="language-plaintext highlighter-rouge">code</code> has <code class="language-plaintext highlighter-rouge">back-ticks around</code> it.</p>

<div class="language-javascript highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">var</span> <span class="nx">s</span> <span class="o">=</span> <span class="dl">"</span><span class="s2">JavaScript syntax highlighting</span><span class="dl">"</span><span class="p">;</span>
<span class="nf">alert</span><span class="p">(</span><span class="nx">s</span><span class="p">);</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">s</span> <span class="o">=</span> <span class="sh">"</span><span class="s">Python syntax highlighting</span><span class="sh">"</span>
<span class="k">print</span> <span class="n">s</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>No language indicated, so no syntax highlighting.
But let's throw in a &lt;b&gt;tag&lt;/b&gt;.
</code></pre></div></div>

<p>Colons can be used to align columns.</p>

<table>
  <thead>
    <tr>
      <th>Tables</th>
      <th style="text-align: center">Are</th>
      <th style="text-align: right">Cool</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>col 3 is</td>
      <td style="text-align: center">right-aligned</td>
      <td style="text-align: right">$1600</td>
    </tr>
    <tr>
      <td>col 2 is</td>
      <td style="text-align: center">centered</td>
      <td style="text-align: right">$12</td>
    </tr>
    <tr>
      <td>zebra stripes</td>
      <td style="text-align: center">are neat</td>
      <td style="text-align: right">$1</td>
    </tr>
  </tbody>
</table>

<p>There must be at least 3 dashes separating each header cell.
The outer pipes (|) are optional, and you don’t need to make the
raw Markdown line up prettily. You can also use inline Markdown.</p>

<table>
  <thead>
    <tr>
      <th>Markdown</th>
      <th>Less</th>
      <th>Pretty</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><em>Still</em></td>
      <td><code class="language-plaintext highlighter-rouge">renders</code></td>
      <td><strong>nicely</strong></td>
    </tr>
    <tr>
      <td>1</td>
      <td>2</td>
      <td>3</td>
    </tr>
  </tbody>
</table>

<blockquote>
  <p>Blockquotes are very handy in email to emulate reply text.
This line is part of the same quote.</p>
</blockquote>

<p>Quote break.</p>

<blockquote>
  <p>This is a very long line that will still be quoted properly when it wraps. Oh boy let’s keep writing to make sure this is long enough to actually wrap for everyone. Oh, you can <em>put</em> <strong>Markdown</strong> into a blockquote.</p>
</blockquote>

<p>Here’s a line for us to start with.</p>

<p>This line is separated from the one above by two newlines, so it will be a <em>separate paragraph</em>.</p>

<p>This line is also a separate paragraph, but…
This line is only separated by a single newline, so it’s a separate line in the <em>same paragraph</em>.</p>]]></content><author><name>Al-folio</name></author><summary type="html"><![CDATA[an example of a distill-style blog post and main elements]]></summary></entry></feed>